{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pseudos(data, feature_list, y_name):\n",
    "    for feature in feature_list:\n",
    "        print(feature)\n",
    "        feature_pseudo = data.groupby([feature], as_index=False)[[y_name]].mean()\n",
    "        feature_pseudo.rename(columns={y_name: 'pseudovar'}, inplace=True)\n",
    "        \n",
    "        data[f'{feature}_pseudo'] = np.nan\n",
    "        data.loc[:, f'{feature}_pseudo'] = data.merge(feature_pseudo, how='left', on=feature)['pseudovar']\n",
    "        \n",
    "        print(f'{feature}_pseudo was added')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_test_pseudos(test, data, feature_list, y_name):\n",
    "    for feature in feature_list:\n",
    "        print(feature)\n",
    "        feature_pseudo = data.groupby([feature], as_index=False)[[y_name]].mean()\n",
    "        feature_pseudo.rename(columns={y_name: 'pseudovar'}, inplace=True)\n",
    "        \n",
    "        test[f'{feature}_pseudo'] = np.nan\n",
    "        test.loc[:, f'{feature}_pseudo'] = test.merge(feature_pseudo, how='left', on=feature)['pseudovar']\n",
    "        \n",
    "        print(f'{feature}_pseudo was added')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cm(data, features_list):\n",
    "    cm = np.corrcoef(pd.DataFrame(np.hstack([data[features_list], data[['Price',]]]), columns=features_list + ['Price']).values.T)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,9))  \n",
    "    sns.set(font_scale=1)\n",
    "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', \n",
    "                     annot_kws={'size' : 9.5}, \n",
    "                     yticklabels=features_list + ['Price'], \n",
    "                     xticklabels=features_list + ['Price'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(data):\n",
    "    data.loc[data['Rooms'] == 19, 'Rooms'] = 1\n",
    "    data.loc[data['Rooms'] == 6, 'Rooms'] = 2\n",
    "    data.loc[data['Rooms'] == 10, 'Rooms'] = 2\n",
    "\n",
    "    data.loc[data['Id'].isin([28, 2307, 11602]), 'Square'] = data['Square'] / 10\n",
    "    data.loc[data['Id'].isin([28, 2307, 11602]), 'LifeSquare'] = data['LifeSquare'] / 10\n",
    "    data.loc[data['LifeSquare'] > 1000, 'LifeSquare'] = data['LifeSquare'] / 100\n",
    "\n",
    "    data.loc[data['Id'].isin([14990, 15886]), 'LifeSquare'] = np.NaN\n",
    "    data.loc[data['LifeSquare'] > data['Square'], 'LifeSquare'] = np.NaN\n",
    "\n",
    "    sup_df = data[['Rooms', 'Square', 'LifeSquare']]\n",
    "    sup_df['ls_percent'] = data['LifeSquare'] / data['Square']\n",
    "    sup_df = sup_df.groupby(['Rooms'], as_index=False)['ls_percent'].median()\n",
    "    data.loc[data['LifeSquare'].isna(), 'new_LifeSquare'] = data.loc[data['LifeSquare'].isna(), ['Rooms', 'Square']].merge(sup_df, how='left', on='Rooms')['ls_percent'].values * data.loc[data['LifeSquare'].isna(), ['Rooms', 'Square']].merge(sup_df, how='left', on='Rooms')['Square'].values\n",
    "    data.loc[~data['LifeSquare'].isna(), 'new_LifeSquare'] = data.loc[~data['LifeSquare'].isna(), 'LifeSquare']\n",
    "\n",
    "    data.loc[data['HouseYear'] == 20052011, 'HouseYear'] = (2005 + 2011)/2\n",
    "    data.loc[data['HouseYear'] == 4968, 'HouseYear'] = data['HouseYear'].median()\n",
    "    \n",
    "    # data.loc[:, 'Price_log'] = np.log(data['Price'])\n",
    "\n",
    "    data = add_pseudos(data, ['Ecology_2', 'Ecology_3', 'DistrictId', 'Helthcare_2', 'Social_2', 'Shops_2'], 'Price')  # можно удалить \"data = \"\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecology_2\n",
      "Ecology_2_pseudo was added\n",
      "Ecology_3\n",
      "Ecology_3_pseudo was added\n",
      "DistrictId\n",
      "DistrictId_pseudo was added\n",
      "Helthcare_2\n",
      "Helthcare_2_pseudo was added\n",
      "Social_2\n",
      "Social_2_pseudo was added\n",
      "Shops_2\n",
      "Shops_2_pseudo was added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_prepared = prepare_train_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['Rooms', 'Square', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear', 'Ecology_1', 'new_LifeSquare',\n",
    "       'DistrictId_pseudo', 'Ecology_2_pseudo', 'Ecology_3_pseudo', 'Helthcare_2_pseudo', 'Social_2', 'Social_3', 'Shops_1', 'Shops_2_pseudo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_cm(data, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_prepared.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_prepared[features_list].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(test, data):\n",
    "\n",
    "    test.loc[test['Rooms'] == 17, 'Rooms'] = 2\n",
    "    test.loc[test['Id'] == 170, 'Square'] = test.loc[test['Id'] == 170, 'LifeSquare'] / 0.628714\n",
    "\n",
    "    test.loc[test['Square'] < 10, 'Square'] = test.loc[test['Square'] <10 , 'Square'] * 10\n",
    "\n",
    "    test.loc[test['Square'] < 10, 'Square'] = test.loc[test['Square'] <10 , 'Square'] * 10\n",
    "    test.loc[(test['Square'] < 50) & (test['Rooms'] > 2), 'Rooms'] = 2\n",
    "    test.loc[test['Id'] == 6060, 'Rooms'] = 2\n",
    "\n",
    "    test.loc[(test['LifeSquare'] < test['Square'] / 4), 'LifeSquare'] = np.NaN\n",
    "    test.loc[test['LifeSquare'] > test['Square'], 'LifeSquare'] = np.NaN\n",
    "\n",
    "    sup_df = test[['Rooms', 'Square', 'LifeSquare']]\n",
    "    sup_df['ls_percent'] = test['LifeSquare'] / test['Square']\n",
    "    sup_df = sup_df.groupby(['Rooms'], as_index=False)['ls_percent'].median()\n",
    "    test.loc[test['LifeSquare'].isna(), 'new_LifeSquare'] = test.loc[test['LifeSquare'].isna(), ['Rooms', 'Square']].merge(sup_df, how='left', on='Rooms')['ls_percent'].values * test.loc[test['LifeSquare'].isna(), ['Rooms', 'Square']].merge(sup_df, how='left', on='Rooms')['Square'].values\n",
    "    test.loc[~test['LifeSquare'].isna(), 'new_LifeSquare'] = test.loc[~test['LifeSquare'].isna(), 'LifeSquare']\n",
    "\n",
    "    test = add_test_pseudos(test, data, ['Ecology_2', 'Ecology_3', 'DistrictId', 'Helthcare_2', 'Social_2', 'Shops_2'], 'Price')  # можно удалить \"data = \"\n",
    "    test.loc[test['DistrictId_pseudo'].isna(), 'DistrictId_pseudo'] = data['DistrictId_pseudo'].mean()\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecology_2\n",
      "Ecology_2_pseudo was added\n",
      "Ecology_3\n",
      "Ecology_3_pseudo was added\n",
      "DistrictId\n",
      "DistrictId_pseudo was added\n",
      "Helthcare_2\n",
      "Helthcare_2_pseudo was added\n",
      "Social_2\n",
      "Social_2_pseudo was added\n",
      "Shops_2\n",
      "Shops_2_pseudo was added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "test = prepare_test(test, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 16 columns):\n",
      "Rooms                 5000 non-null float64\n",
      "Square                5000 non-null float64\n",
      "KitchenSquare         5000 non-null float64\n",
      "Floor                 5000 non-null int64\n",
      "HouseFloor            5000 non-null float64\n",
      "HouseYear             5000 non-null int64\n",
      "Ecology_1             5000 non-null float64\n",
      "new_LifeSquare        5000 non-null float64\n",
      "DistrictId_pseudo     5000 non-null float64\n",
      "Ecology_2_pseudo      5000 non-null float64\n",
      "Ecology_3_pseudo      5000 non-null float64\n",
      "Helthcare_2_pseudo    5000 non-null float64\n",
      "Social_2              5000 non-null int64\n",
      "Social_3              5000 non-null int64\n",
      "Shops_1               5000 non-null int64\n",
      "Shops_2_pseudo        5000 non-null float64\n",
      "dtypes: float64(11), int64(5)\n",
      "memory usage: 625.1 KB\n"
     ]
    }
   ],
   "source": [
    "test[features_list].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['Rooms', 'Square', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear', 'Ecology_1', 'new_LifeSquare',\n",
    "       'DistrictId_pseudo', 'Ecology_2_pseudo', 'Ecology_3_pseudo', 'Helthcare_2_pseudo', 'Social_2', 'Social_3', 'Shops_1', 'Shops_2_pseudo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=16,\n",
    "           max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "           min_impurity_split=None, min_samples_leaf=1,\n",
    "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=400, n_jobs=None, oob_score=False,\n",
    "           random_state=100, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=16,\n",
       "           max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=400, n_jobs=None, oob_score=False,\n",
       "           random_state=100, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(data_prepared[features_list], data_prepared['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(estimator, data_prepared[features_list], data_prepared['Price'], cv=15, scoring='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Price'] = estimator.predict(test[features_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, ['Id', 'Price']].to_csv('ANikitina_predictions.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import clone \n",
    "\n",
    "# def drop_col_feat_imp(model, X_train, y_train, random_state = 12):\n",
    "    \n",
    "#     # clone the model to have the exact same specification as the one initially trained\n",
    "#     model_clone = clone(model)\n",
    "#     # set random_state for comparability\n",
    "#     model_clone.random_state = random_state\n",
    "#     # training and scoring the benchmark model\n",
    "#     model_clone.fit(X_train, y_train)\n",
    "#     benchmark_score = model_clone.score(X_train, y_train)\n",
    "#     # list for storing feature importances\n",
    "#     importances = []\n",
    "    \n",
    "#     # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "#     for col in X_train.columns:\n",
    "#         model_clone = clone(model)\n",
    "#         model_clone.random_state = random_state\n",
    "#         model_clone.fit(X_train.drop(col, axis = 1), y_train)\n",
    "#         drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)\n",
    "#         importances.append(benchmark_score - drop_col_score)\n",
    "    \n",
    "#     importances_df = pd.DataFrame(importances, index=X_train.columns)\n",
    "#     return importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_df = drop_col_feat_imp(estimator, data[features_list], data['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11154013, 0.2368304 , 0.04308136, 0.02607578, 0.02727534,\n",
       "       0.04033581, 0.02755906, 0.11462304, 0.19562722, 0.00024704,\n",
       "       0.00106414, 0.02410976, 0.0736775 , 0.04907381, 0.02717336,\n",
       "       0.00170626])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
